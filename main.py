#!/usr/bin/env python3
"""
AI-powered presentation video generator from PDF slides
"""

import os
import sys
from pathlib import Path
from typing import List, Optional
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

from dotenv import load_dotenv
from pdf2image import convert_from_path
from PIL import Image
from google import genai
from google.genai import types
import wave
import cv2
import numpy as np
try:
    from moviepy.editor import VideoFileClip, concatenate_videoclips
    from moviepy.audio.io.AudioFileClip import AudioFileClip
except ImportError:
    VideoFileClip = None
    concatenate_videoclips = None
    AudioFileClip = None
import tempfile
import shutil
from pptx import Presentation

# Load environment variables
load_dotenv()

class PresentationVideoGenerator:
    def __init__(self, project_name: str):
        self.genai_client = genai.Client(api_key=os.getenv("GOOGLE_API_KEY"))
        self.project_name = project_name
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆ
        self.base_output_dir = Path("output") / project_name
        self.txt_dir = self.base_output_dir / "txt"
        self.wav_dir = self.base_output_dir / "wav"
        self.mp4_dir = self.base_output_dir / "mp4"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        self.base_output_dir.mkdir(parents=True, exist_ok=True)
        self.txt_dir.mkdir(exist_ok=True)
        self.wav_dir.mkdir(exist_ok=True)
        self.mp4_dir.mkdir(exist_ok=True)
        
    def get_corresponding_pdf(self, pptx_path: str) -> str:
        """PPTXãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾å¿œã™ã‚‹PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’å–å¾—"""
        base_name = os.path.splitext(os.path.basename(pptx_path))[0]
        pdf_path = Path("slides/pdf") / f"{base_name}.pdf"
        
        if not pdf_path.exists():
            raise FileNotFoundError(f"Corresponding PDF file not found: {pdf_path}")
        
        logger.info(f"Found corresponding PDF: {pdf_path}")
        return str(pdf_path)
    
    def extract_speaker_notes_from_pptx(self, pptx_path: str) -> List[Optional[str]]:
        """PPTXãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç™ºè¡¨è€…ãƒãƒ¼ãƒˆã‚’æŠ½å‡º"""
        logger.info(f"Extracting speaker notes from PPTX: {pptx_path}")
        try:
            presentation = Presentation(pptx_path)
            speaker_notes = []
            
            for i, slide in enumerate(presentation.slides, 1):
                note_text = None
                
                # ç™ºè¡¨è€…ãƒãƒ¼ãƒˆãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                if slide.has_notes_slide:
                    notes_slide = slide.notes_slide
                    if notes_slide.notes_text_frame and notes_slide.notes_text_frame.text:
                        note_text = notes_slide.notes_text_frame.text.strip()
                        # ç©ºæ–‡å­—åˆ—ã‚„ç©ºç™½ã®ã¿ã®å ´åˆã¯Noneã¨ã—ã¦æ‰±ã†
                        if not note_text:
                            note_text = None
                        else:
                            logger.info(f"Found speaker notes for slide {i}: {len(note_text)} characters")
                
                if note_text is None:
                    logger.info(f"No speaker notes found for slide {i}")
                
                speaker_notes.append(note_text)
            
            logger.info(f"Extracted speaker notes for {len(speaker_notes)} slides")
            return speaker_notes
            
        except Exception as e:
            logger.error(f"Error extracting speaker notes from PPTX: {e}")
            raise
    
    def extract_images_from_pdf(self, pdf_path: str) -> List[Image.Image]:
        """PDFã‹ã‚‰å„ãƒšãƒ¼ã‚¸ã®ç”»åƒã‚’æŠ½å‡º"""
        logger.info(f"Extracting images from PDF: {pdf_path}")
        try:
            images = convert_from_path(pdf_path, dpi=300)
            logger.info(f"Extracted {len(images)} pages from PDF")
            return images
        except Exception as e:
            logger.error(f"Error extracting images from PDF: {e}")
            raise
    
    def get_script_for_slide(self, speaker_note: Optional[str] = None) -> Optional[str]:
        """ã‚¹ãƒ©ã‚¤ãƒ‰ã®åŸç¨¿ã‚’å–å¾—ï¼ˆç™ºè¡¨è€…ãƒãƒ¼ãƒˆã®ã¿ä½¿ç”¨ï¼‰"""
        
        # ç™ºè¡¨è€…ãƒãƒ¼ãƒˆãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        if speaker_note is not None and speaker_note.strip():
            return speaker_note.strip()
        
        # ç™ºè¡¨è€…ãƒãƒ¼ãƒˆãŒãªã„å ´åˆã¯Noneã‚’è¿”ã™
        return None
    
    
    def text_to_speech(self, text: str, output_path: str) -> str:
        """Geminiã®TTSã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã«å¤‰æ›"""
        logger.info(f"Converting text to speech: {len(text)} characters")
        
        try:
            # Gemini TTSã®å®Ÿè£…
            response = self.genai_client.models.generate_content(
                model="gemini-2.5-flash-preview-tts",
                contents=text,
                config=types.GenerateContentConfig(
                    response_modalities=["AUDIO"],
                    speech_config=types.SpeechConfig(
                        voice_config=types.VoiceConfig(
                            prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                voice_name="Kore",
                            )
                        )
                    ),
                )
            )
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            audio_data = response.candidates[0].content.parts[0].inline_data.data
            
            # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
            with wave.open(output_path, "wb") as wf:
                wf.setnchannels(1)
                wf.setsampwidth(2)
                wf.setframerate(24000)
                wf.writeframes(audio_data)
            
            logger.info(f"Audio saved to: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"Error in text-to-speech conversion: {e}")
            raise
    
    def create_video_from_slide_and_audio(self, image: Image.Image, audio_path: Optional[str], output_path: str, duration: float = 3.0) -> str:
        """ã‚¹ãƒ©ã‚¤ãƒ‰ç”»åƒã¨éŸ³å£°ï¼ˆã¾ãŸã¯ç„¡éŸ³ï¼‰ã‚’åˆæˆã—ã¦å‹•ç”»ã‚’ä½œæˆ"""
        if audio_path:
            logger.info(f"Creating video from slide and audio: {output_path}")
        else:
            logger.info(f"Creating silent video from slide: {output_path} (duration: {duration}s)")
        
        try:
            # ç”»åƒã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆã‚µã‚¤ã‚ºèª¿æ•´ï¼‰
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
                # é«˜ã•ã‚’2ã§å‰²ã‚Šåˆ‡ã‚Œã‚‹ã‚ˆã†ã«èª¿æ•´
                width, height = image.size
                if height % 2 != 0:
                    height -= 1
                if width % 2 != 0:
                    width -= 1
                
                # ç”»åƒã‚’ãƒªã‚µã‚¤ã‚º
                resized_image = image.resize((width, height), Image.LANCZOS)
                resized_image.save(temp_file.name)
                temp_image_path = temp_file.name
            
            # FFmpegã‚’ä½¿ç”¨ã—ã¦å‹•ç”»ã‚’ä½œæˆ
            import subprocess
            
            if audio_path:
                # éŸ³å£°ã®é•·ã•ã‚’å–å¾—ï¼ˆffprobeã‚’ä½¿ç”¨ï¼‰
                duration_cmd = [
                    'ffprobe', '-v', 'error', '-show_entries', 'format=duration', 
                    '-of', 'default=noprint_wrappers=1:nokey=1', audio_path
                ]
                duration_result = subprocess.run(duration_cmd, capture_output=True, text=True)
                duration = float(duration_result.stdout.strip())
                
                # FFmpegã§ç”»åƒã¨éŸ³å£°ã‚’åˆæˆ
                ffmpeg_cmd = [
                    'ffmpeg', '-y',  # -y for overwrite
                    '-loop', '1',    # Loop the image
                    '-i', temp_image_path,  # Input image
                    '-i', audio_path,       # Input audio
                    '-c:v', 'libx264',      # Video codec
                    '-c:a', 'aac',          # Audio codec
                    '-t', str(duration),    # Duration
                    '-pix_fmt', 'yuv420p',  # Pixel format for compatibility
                    '-r', '1',              # Frame rate (1fps for static image)
                    '-shortest',            # Stop encoding when the shortest input ends
                    output_path
                ]
            else:
                # ç„¡éŸ³å‹•ç”»ã‚’ä½œæˆ
                ffmpeg_cmd = [
                    'ffmpeg', '-y',  # -y for overwrite
                    '-loop', '1',    # Loop the image
                    '-i', temp_image_path,  # Input image
                    '-f', 'lavfi',   # Generate silent audio
                    '-i', 'anullsrc=channel_layout=mono:sample_rate=48000',  # Silent audio
                    '-c:v', 'libx264',      # Video codec
                    '-c:a', 'aac',          # Audio codec
                    '-t', str(duration),    # Duration
                    '-pix_fmt', 'yuv420p',  # Pixel format for compatibility
                    '-r', '1',              # Frame rate (1fps for static image)
                    '-shortest',            # Stop encoding when the shortest input ends
                    output_path
                ]
            
            result = subprocess.run(ffmpeg_cmd, capture_output=True, text=True)
            if result.returncode != 0:
                logger.error(f"FFmpeg error: {result.stderr}")
                raise subprocess.CalledProcessError(result.returncode, ffmpeg_cmd, result.stderr)
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            os.unlink(temp_image_path)
            
            logger.info(f"Video created: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"Error creating video: {e}")
            raise
    
    def combine_videos(self, video_paths: List[str], output_path: str) -> str:
        """è¤‡æ•°ã®å‹•ç”»ã‚’çµåˆã—ã¦æœ€çµ‚çš„ãªãƒ—ãƒ¬ã‚¼ãƒ³å‹•ç”»ã‚’ä½œæˆ"""
        logger.info(f"Combining {len(video_paths)} videos into final presentation")
        
        try:
            # FFmpegã‚’ä½¿ç”¨ã—ã¦å‹•ç”»ã‚’çµåˆ
            import subprocess
            
            # å…¥åŠ›ãƒªã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            input_list_path = self.base_output_dir / "input_list.txt"
            with open(input_list_path, 'w') as f:
                for video_path in video_paths:
                    f.write(f"file '{os.path.abspath(video_path)}'\n")
            
            # FFmpegã§å‹•ç”»ã‚’çµåˆ
            ffmpeg_cmd = [
                'ffmpeg', '-y',  # -y for overwrite
                '-f', 'concat',  # Concat format
                '-safe', '0',    # Allow absolute paths
                '-i', str(input_list_path),  # Input list
                '-c', 'copy',    # Copy streams without re-encoding
                output_path
            ]
            
            subprocess.run(ffmpeg_cmd, check=True, capture_output=True)
            
            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            os.unlink(input_list_path)
            
            logger.info(f"Final presentation video created: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"Error combining videos: {e}")
            raise
    
    def generate_presentation_video(self, file_path: str) -> str:
        """PPTXã‹ã‚‰ãƒ—ãƒ¬ã‚¼ãƒ³å‹•ç”»ã‚’ç”Ÿæˆã™ã‚‹ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
        logger.info(f"Starting presentation video generation from: {file_path}")
        
        try:
            # PPTXå‡¦ç†
            logger.info("Processing PPTX file")
            
            # 1. ç™ºè¡¨è€…ãƒãƒ¼ãƒˆã‚’æŠ½å‡º
            speaker_notes = self.extract_speaker_notes_from_pptx(file_path)
            
            # 2. å¯¾å¿œã™ã‚‹PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            corresponding_pdf_path = self.get_corresponding_pdf(file_path)
            
            # 3. PDFã‹ã‚‰ç”»åƒã‚’æŠ½å‡º
            images = self.extract_images_from_pdf(corresponding_pdf_path)
            
            video_paths = []
            
            # 4. å„ã‚¹ãƒ©ã‚¤ãƒ‰ã«å¯¾ã—ã¦å‡¦ç†
            for i, image in enumerate(images, 1):
                logger.info(f"Processing slide {i}/{len(images)}")
                
                # 5. åŸç¨¿å–å¾—ï¼ˆç™ºè¡¨è€…ãƒãƒ¼ãƒˆã®ã¿ä½¿ç”¨ï¼‰
                speaker_note = speaker_notes[i-1] if i <= len(speaker_notes) else None
                script = self.get_script_for_slide(speaker_note)
                
                if script:
                    # åŸç¨¿ãŒã‚ã‚‹å ´åˆã®å‡¦ç†
                    logger.info(f"Using speaker notes for slide {i}: {len(script)} characters")
                    
                    # åŸç¨¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    script_path = self.txt_dir / f"slide_{i:03d}_script.txt"
                    with open(script_path, 'w', encoding='utf-8') as f:
                        f.write(script)
                    logger.info(f"Script saved to: {script_path}")
                    
                    # 6. éŸ³å£°ç”Ÿæˆ
                    audio_path = self.wav_dir / f"slide_{i:03d}_audio.wav"
                    self.text_to_speech(script, str(audio_path))
                    
                    # 7. å‹•ç”»ç”Ÿæˆï¼ˆéŸ³å£°ä»˜ãï¼‰
                    video_path = self.mp4_dir / f"slide_{i:03d}_video.mp4"
                    self.create_video_from_slide_and_audio(image, str(audio_path), str(video_path))
                    video_paths.append(str(video_path))
                else:
                    # åŸç¨¿ãŒãªã„å ´åˆã¯3ç§’é–“ã®ç„¡éŸ³å‹•ç”»ã‚’ä½œæˆ
                    logger.info(f"No speaker notes for slide {i}, creating 3-second silent video")
                    
                    # 7. ç„¡éŸ³å‹•ç”»ç”Ÿæˆï¼ˆ3ç§’ï¼‰
                    video_path = self.mp4_dir / f"slide_{i:03d}_video.mp4"
                    self.create_video_from_slide_and_audio(image, None, str(video_path), duration=3.0)
                    video_paths.append(str(video_path))
            
            # 8. å‹•ç”»ã‚’çµåˆã—ã¦æœ€çµ‚å‡ºåŠ›
            final_video_name = f"{self.project_name}.mp4"
            final_video_path = self.base_output_dir / final_video_name
            self.combine_videos(video_paths, str(final_video_path))
            
            # 9. PPTXã§ä½¿ç”¨ã—ãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
            if corresponding_pdf_path:
                logger.info(f"Used corresponding PDF: {corresponding_pdf_path}")
            
            logger.info(f"Presentation video generation completed: {final_video_path}")
            return str(final_video_path)
            
        except Exception as e:
            logger.error(f"Error in presentation video generation: {e}")
            raise


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python main.py <pptxãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹>")
        print("å¯¾å¿œå½¢å¼: PowerPoint (.pptx) ã®ã¿")
        sys.exit(1)
    
    file_path = sys.argv[1]
    
    if not os.path.exists(file_path):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        sys.exit(1)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆPPTX ã®ã¿ï¼‰
    file_extension = os.path.splitext(file_path)[1].lower()
    if file_extension != '.pptx':
        print(f"ã‚¨ãƒ©ãƒ¼: ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {file_extension}")
        print("å¯¾å¿œå½¢å¼: PowerPoint (.pptx) ã®ã¿")
        sys.exit(1)
    
    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ç”Ÿæˆ
    project_name = Path(file_path).stem
    
    # å¿…è¦ãªAPI KEYã®ç¢ºèª
    if not os.getenv("GOOGLE_API_KEY"):
        print("ã‚¨ãƒ©ãƒ¼: ç’°å¢ƒå¤‰æ•°ã«GOOGLE_API_KEYãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        sys.exit(1)
    
    generator = PresentationVideoGenerator(project_name)
    
    try:
        final_video = generator.generate_presentation_video(file_path)
        print(f"âœ… ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»ãŒæ­£å¸¸ã«ç”Ÿæˆã•ã‚Œã¾ã—ãŸ: {final_video}")
        
        # å‡¦ç†çµæœã®è¿½åŠ æƒ…å ±
        base_name = Path(file_path).stem
        used_pdf_path = f"slides/pdf/{base_name}.pdf"
        print("ğŸ“ è£œè¶³: ç™ºè¡¨è€…ãƒãƒ¼ãƒˆãŒã‚ã‚‹ã‚¹ãƒ©ã‚¤ãƒ‰ã¯éŸ³å£°ä»˜ãã€ãƒãƒ¼ãƒˆãŒãªã„ã‚¹ãƒ©ã‚¤ãƒ‰ã¯3ç§’é–“ã®ç„¡éŸ³è¡¨ç¤ºã«ãªã‚Šã¾ã™")
        print(f"ğŸ“„ ä½¿ç”¨ã—ãŸPDFãƒ•ã‚¡ã‚¤ãƒ«: {used_pdf_path}")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()